#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å®Œæ•´çš„PySparkç¯å¢ƒæ£€æµ‹è„šæœ¬
æ£€æµ‹æ‰€æœ‰ä¾èµ–åº“çš„ç‰ˆæœ¬å’Œå…¼å®¹æ€§é—®é¢˜
"""

import sys
import os
import subprocess
import json
from datetime import datetime


class SparkEnvironmentChecker:
    def __init__(self):
        self.results = {
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "system_info": {},
            "python_info": {},
            "java_info": {},
            "installed_packages": {},
            "compatibility_issues": [],
            "recommendations": []
        }

    def print_section(self, title):
        """æ‰“å°åˆ†èŠ‚æ ‡é¢˜"""
        print("\n" + "=" * 60)
        print(f" {title} ")
        print("=" * 60)

    def check_python_version(self):
        """æ£€æŸ¥Pythonç‰ˆæœ¬"""
        self.print_section("Pythonç‰ˆæœ¬æ£€æŸ¥")

        python_version = sys.version_info
        python_version_str = f"{python_version.major}.{python_version.minor}.{python_version.micro}"

        self.results["python_info"] = {
            "version": python_version_str,
            "version_info": str(sys.version),
            "executable": sys.executable,
            "prefix": sys.prefix
        }

        print(f"Pythonç‰ˆæœ¬: {python_version_str}")
        print(f"Pythonè·¯å¾„: {sys.executable}")

        # æ£€æŸ¥Pythonç‰ˆæœ¬å…¼å®¹æ€§
        if python_version.major == 3 and python_version.minor == 12:
            print("")
            self.results["compatibility_issues"].append(
                ""
            )
            self.results["recommendations"].append(
                ""
            )
        elif python_version.major == 3 and python_version.minor < 9:
            print("âš ï¸  è­¦å‘Š: Pythonç‰ˆæœ¬è¿‡ä½ï¼ŒPySpark 4.0éœ€è¦Python 3.9+")
            self.results["compatibility_issues"].append(
                f"Python {python_version_str}å¤ªæ—§ï¼ŒPySpark 4.0.0éœ€è¦Python 3.9+"
            )

    def check_java_version(self):
        """æ£€æŸ¥Javaç‰ˆæœ¬"""
        self.print_section("Javaç¯å¢ƒæ£€æŸ¥")

        java_home = os.environ.get('JAVA_HOME', 'æœªè®¾ç½®')
        print(f"JAVA_HOME: {java_home}")

        try:
            # æ£€æŸ¥javaå‘½ä»¤
            # --- FIX START ---
            # 1. ç§»é™¤äº† stderr=subprocess.STDOUT å‚æ•°
            # 2. java -version çš„è¾“å‡ºåœ¨ stderr, æ‰€ä»¥åé¢ä¼šä» result.stderr è¯»å–
            result = subprocess.run(['java', '-version'],
                                    capture_output=True,
                                    text=True,
                                    check=False)  # ä½¿ç”¨ check=False é¿å…åœ¨è¿”å›é0ç æ—¶æŠ›å‡ºå¼‚å¸¸

            # java -version å‘½ä»¤å³ä½¿æˆåŠŸä¹Ÿä¼šè¿”å›é0é€€å‡ºç ï¼Œæ‰€ä»¥æˆ‘ä»¬æ£€æŸ¥è¾“å‡ºå†…å®¹
            # å¹¶ä¸”å®ƒçš„è¾“å‡ºåœ¨ stderr
            java_output = result.stderr
            if "version" in java_output.lower():
                print(f"Javaç‰ˆæœ¬ä¿¡æ¯:\n{java_output}")

                # è§£æJavaç‰ˆæœ¬
                if 'version "1.8' in java_output or 'version "8"' in java_output:
                    java_version = "8"
                elif 'version "11' in java_output:
                    java_version = "11"
                elif 'version "17' in java_output:
                    java_version = "17"
                else:
                    java_version = "unknown"

                self.results["java_info"] = {
                    "java_home": java_home,
                    "version": java_version,
                    "output": java_output
                }

                print(f"âœ“ Java {java_version}å·²å®‰è£…")

            else:
                print("âœ— Javaæœªæ‰¾åˆ°æˆ–æ— æ³•æ‰§è¡Œ")
                print(f"  - Stderr: {result.stderr}")
                print(f"  - Stdout: {result.stdout}")
                self.results["compatibility_issues"].append("Javaæœªå®‰è£…æˆ–æ— æ³•æ‰§è¡Œ")
                self.results["recommendations"].append("è¯·å®‰è£…Java 8ã€11æˆ–17")
            # --- FIX END ---

        except FileNotFoundError:
            print("âœ— æ— æ³•æ‰§è¡Œjavaå‘½ä»¤")
            self.results["compatibility_issues"].append("æ‰¾ä¸åˆ°javaå‘½ä»¤")
            self.results["recommendations"].append("è¯·å®‰è£…Javaå¹¶è®¾ç½®JAVA_HOMEç¯å¢ƒå˜é‡")
        except Exception as e:
            print(f"âœ— æ£€æŸ¥Javaæ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")

    def check_package_versions(self):
        """æ£€æŸ¥æ‰€æœ‰ç›¸å…³PythonåŒ…çš„ç‰ˆæœ¬"""
        self.print_section("PythonåŒ…ç‰ˆæœ¬æ£€æŸ¥")

        packages_to_check = {
            'pyspark': {
                'min_for_py312': '4.0.0',
                'pandas_min': {'3.5': '1.0.5', '4.0': '2.0.0'},
                'numpy_min': {'3.5': '1.15', '4.0': '1.21'},
                'pyarrow_min': {'3.5': '4.0.0', '4.0': '11.0.0'}
            },
            'pandas': None,
            'numpy': None,
            'scikit-learn': None,
            'pyarrow': None,
            'py4j': None
        }

        for package_name in packages_to_check:
            try:
                # Special case for scikit-learn import name
                import_name = 'sklearn' if package_name == 'scikit-learn' else package_name
                module = __import__(import_name)
                version = getattr(module, '__version__', 'unknown')
                print(f"âœ“ {package_name}: {version}")
                self.results["installed_packages"][package_name] = version

            except ImportError:
                print(f"âœ— {package_name}: æœªå®‰è£…")
                self.results["installed_packages"][package_name] = "not installed"

        # æ£€æŸ¥ç‰ˆæœ¬å…¼å®¹æ€§
        self._check_version_compatibility()

    def _check_version_compatibility(self):
        """æ£€æŸ¥å„ä¸ªåŒ…ä¹‹é—´çš„ç‰ˆæœ¬å…¼å®¹æ€§"""
        print("\nç‰ˆæœ¬å…¼å®¹æ€§åˆ†æ:")

        pyspark_version = self.results["installed_packages"].get("pyspark", "not installed")
        pandas_version = self.results["installed_packages"].get("pandas", "not installed")
        numpy_version = self.results["installed_packages"].get("numpy", "not installed")
        python_version = sys.version_info

        if pyspark_version != "not installed":
            # è§£æPySparkç‰ˆæœ¬
            try:
                major_version = int(pyspark_version.split('.')[0])
                minor_version = int(pyspark_version.split('.')[1])

                # æ£€æŸ¥Python 3.12å…¼å®¹æ€§
                if python_version.minor == 12 and major_version < 4:
                    print(f"âŒ ä¸¥é‡é—®é¢˜: PySpark {pyspark_version}ä¸æ”¯æŒPython 3.12!")
                    self.results["compatibility_issues"].append(
                        f"PySpark {pyspark_version}ä¸Python 3.12ä¸å…¼å®¹"
                    )

                # æ£€æŸ¥PySpark 4.0çš„ä¾èµ–è¦æ±‚
                if major_version >= 4:
                    print(f"â„¹ï¸  PySpark 4.0+éœ€è¦:")
                    print("   - Pandas >= 2.0.0")
                    print("   - NumPy >= 1.21")
                    print("   - PyArrow >= 11.0.0")

                    # æ£€æŸ¥Pandasç‰ˆæœ¬
                    if pandas_version != "not installed":
                        pandas_major = int(pandas_version.split('.')[0])
                        if pandas_major < 2:
                            print(f"   âŒ Pandas {pandas_version} < 2.0.0")
                            self.results["compatibility_issues"].append(
                                f"PySpark 4.0éœ€è¦Pandas >= 2.0.0ï¼Œå½“å‰æ˜¯{pandas_version}"
                            )

                    # æ£€æŸ¥NumPyç‰ˆæœ¬
                    if numpy_version != "not installed":
                        numpy_parts = numpy_version.split('.')
                        numpy_major = int(numpy_parts[0])
                        numpy_minor = int(numpy_parts[1])
                        if numpy_major == 1 and numpy_minor < 21:
                            print(f"   âŒ NumPy {numpy_version} < 1.21")
                            self.results["compatibility_issues"].append(
                                f"PySpark 4.0éœ€è¦NumPy >= 1.21ï¼Œå½“å‰æ˜¯{numpy_version}"
                            )

                elif major_version == 3 and minor_version == 5:
                    print(f"â„¹ï¸  PySpark 3.5.xæ”¯æŒ:")
                    print("   - Python 3.8-3.11")
                    print("   - Pandas >= 1.0.5")
                    print("   - NumPy >= 1.15")

            except (ValueError, IndexError):
                print(f"âš ï¸  æ— æ³•è§£æPySparkç‰ˆæœ¬: {pyspark_version}")

    def test_spark_functionality(self):
        """æµ‹è¯•SparkåŸºæœ¬åŠŸèƒ½"""
        self.print_section("SparkåŠŸèƒ½æµ‹è¯•")

        try:
            from pyspark.sql import SparkSession

            print("åˆ›å»ºSparkSession...")
            spark = SparkSession.builder \
                .appName("EnvironmentTest") \
                .master("local[1]") \
                .getOrCreate()

            spark.sparkContext.setLogLevel("ERROR")

            # æµ‹è¯•1ï¼šåŸºæœ¬rangeæ“ä½œ
            print("æµ‹è¯•1: Rangeæ“ä½œ...")
            df = spark.range(5)
            count = df.count()
            print(f"âœ“ Range count: {count}")

            # æµ‹è¯•2ï¼šDataFrameåˆ›å»º
            print("æµ‹è¯•2: DataFrameåˆ›å»º...")
            test_data = [(1, "A"), (2, "B"), (3, "C")]
            test_df = spark.createDataFrame(test_data, ["id", "value"])
            print("âœ“ DataFrameåˆ›å»ºæˆåŠŸ")

            # æµ‹è¯•3ï¼šShowæ“ä½œï¼ˆæœ€å®¹æ˜“å‡ºé—®é¢˜çš„ï¼‰
            print("æµ‹è¯•3: Showæ“ä½œ...")
            try:
                test_df.show()
                print("âœ“ Showæ“ä½œæˆåŠŸ")
                self.results["spark_test"] = "passed"
            except Exception as e:
                print(f"âœ— Showæ“ä½œå¤±è´¥: {str(e)}")
                self.results["spark_test"] = "failed"
                self.results["compatibility_issues"].append(
                    f"Spark show()æ“ä½œå¤±è´¥: {str(e)}"
                )

            spark.stop()
            print("âœ“ SparkSessionå·²åœæ­¢")

        except Exception as e:
            print(f"âœ— Sparkæµ‹è¯•å¤±è´¥: {str(e)}")
            self.results["spark_test"] = "failed"
            self.results["compatibility_issues"].append(f"Sparkæµ‹è¯•å¤±è´¥: {str(e)}")

    def generate_recommendations(self):
        """ç”Ÿæˆæœ€ç»ˆå»ºè®®"""
        self.print_section("å»ºè®®æ–¹æ¡ˆ")

        python_version = sys.version_info

        if python_version.minor == 12:
            print("\nğŸš¨ æ‚¨æ­£åœ¨ä½¿ç”¨Python 3.12ï¼Œè¿™ä¸æ—§ç‰ˆPySparkä¸å…¼å®¹ã€‚æœ‰ä¸¤ä¸ªè§£å†³æ–¹æ¡ˆï¼š")
            print("\næ–¹æ¡ˆ1ï¼ˆæ¨èï¼‰ï¼šé™çº§Python")
            print("  åœ¨æ‚¨çš„é¡¹ç›®ä¸­ä½¿ç”¨ä¸€ä¸ªPython 3.11çš„ç¯å¢ƒã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨conda:")
            print("  ```bash")
            print("  # ä½¿ç”¨condaåˆ›å»ºPython 3.11ç¯å¢ƒ")
            print("  conda create -n pyspark311 python=3.11")
            print("  conda activate pyspark311")
            print("  pip install pyspark==3.5.1 pandas numpy scikit-learn")
            print("  ```")

            print("\næ–¹æ¡ˆ2ï¼šå‡çº§åˆ°PySpark 4.0")
            print("  ```bash")
            print("  pip uninstall pyspark -y")
            print("  pip install pyspark>=4.0.0")
            print("  # æ³¨æ„ï¼šå¯èƒ½è¿˜éœ€è¦å‡çº§å…¶ä»–ä¾èµ–")
            print("  pip install --upgrade pandas numpy pyarrow")
            print("  ```")

        # è¾“å‡ºæ‰€æœ‰å‘ç°çš„é—®é¢˜
        if self.results["compatibility_issues"]:
            print("\nâš ï¸  å‘ç°çš„å…¼å®¹æ€§é—®é¢˜:")
            for issue in self.results["compatibility_issues"]:
                print(f"  - {issue}")

        # è¾“å‡ºå»ºè®®
        if self.results["recommendations"]:
            print("\nğŸ’¡ å»ºè®®:")
            for rec in self.results["recommendations"]:
                print(f"  - {rec}")

    def save_report(self):
        """ä¿å­˜æ£€æµ‹æŠ¥å‘Š"""
        report_file = "spark_env_check_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

    def run_all_checks(self):
        """è¿è¡Œæ‰€æœ‰æ£€æŸ¥"""
        print("ğŸ” å¼€å§‹PySparkç¯å¢ƒå…¨é¢æ£€æµ‹...")
        print(f"æ£€æµ‹æ—¶é—´: {self.results['timestamp']}")

        # è¿è¡Œå„é¡¹æ£€æŸ¥
        self.check_python_version()
        self.check_java_version()
        self.check_package_versions()
        self.test_spark_functionality()
        self.generate_recommendations()
        self.save_report()

        print("\nâœ… ç¯å¢ƒæ£€æµ‹å®Œæˆï¼")

        # è¿”å›æ˜¯å¦æœ‰ä¸¥é‡é—®é¢˜
        return len(self.results["compatibility_issues"]) == 0


if __name__ == "__main__":
    checker = SparkEnvironmentChecker()
    success = checker.run_all_checks()

    if not success:
        print("\nâŒ å‘ç°å…¼å®¹æ€§é—®é¢˜ï¼Œè¯·æŒ‰ç…§å»ºè®®ä¿®å¤åå†è¿è¡Œæ‚¨çš„ä»£ç ")
        sys.exit(1)
    else:
        print("\nâœ… ç¯å¢ƒæ£€æµ‹é€šè¿‡ï¼Œå¯ä»¥è¿è¡ŒPySparkä»£ç ")
        sys.exit(0)
